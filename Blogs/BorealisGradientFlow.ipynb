{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyP9fLqBQPgcYJB1KXs3Scp/",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/udlbook/udlbook/blob/main/Blogs/BorealisGradientFlow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Gradient flow\n",
    "\n",
    "This notebook replicates some of the results in the the Borealis AI [blog](https://www.borealisai.com/research-blogs/gradient-flow/) on gradient flow.  \n"
   ],
   "metadata": {
    "id": "ucrRRJ4dq8_d"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Import relevant libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import expm\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap"
   ],
   "metadata": {
    "id": "_IQFHZEMZE8T"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Create the three data points that are used to train the linear model in the blog.  Each input point is a column in $\\mathbf{X}$ and consists of the $x$ position in the plot and the value 1, which is used to allow the model to fit bias terms neatly."
   ],
   "metadata": {
    "id": "NwgUP3MSriiJ"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cJNZ2VIcYsD8"
   },
   "outputs": [],
   "source": [
    "X = np.array([[0.2, 0.4, 0.8], [1, 1, 1]])\n",
    "y = np.array([[-0.1], [0.15], [0.3]])\n",
    "D = X.shape[0]\n",
    "I = X.shape[1]\n",
    "\n",
    "print(\"X=\\n\", X)\n",
    "print(\"y=\\n\", y)"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# Draw the three data points\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(X[0:1, :], y.T, \"ro\")\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([-0.5, 0.5])\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "FpFlD4nUZDRt"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Compute the evolution of the residuals, loss, and parameters as a function of time."
   ],
   "metadata": {
    "id": "H2LBR1DasQej"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Discretized time to evaluate quantities at\n",
    "t_all = np.arange(0, 20, 0.01)\n",
    "nT = t_all.shape[0]\n",
    "\n",
    "# Initial parameters, and initial function output at training points\n",
    "phi_0 = np.array([[-0.05], [-0.4]])\n",
    "f_0 = X.T @ phi_0\n",
    "\n",
    "# Precompute pseudoinverse term (not a very sensible numerical implementation, but it works...)\n",
    "XXTInvX = np.linalg.inv(X @ X.T) @ X\n",
    "\n",
    "# Create arrays to hold function at data points over time, residual over time, parameters over time\n",
    "f_all = np.zeros((I, nT))\n",
    "f_minus_y_all = np.zeros((I, nT))\n",
    "phi_t_all = np.zeros((D, nT))\n",
    "\n",
    "# For each time, compute function, residual, and parameters at each time.\n",
    "for t in range(len(t_all)):\n",
    "    f = y + expm(-X.T @ X * t_all[t]) @ (f_0 - y)\n",
    "    f_all[:, t : t + 1] = f\n",
    "    f_minus_y_all[:, t : t + 1] = f - y\n",
    "    phi_t_all[:, t : t + 1] = phi_0 - XXTInvX @ (\n",
    "        np.identity(3) - expm(-X.T @ X * t_all[t])\n",
    "    ) @ (f_0 - y)"
   ],
   "metadata": {
    "id": "wfF_oTS5Z4Wi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the results that were calculated in the previous cell"
   ],
   "metadata": {
    "id": "9jSjOOFutJUE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Plot function at data points\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t_all, np.squeeze(f_all[0, :]), \"r-\", label=\"$f[x_{0},\\phi]$\")\n",
    "ax.plot(t_all, np.squeeze(f_all[1, :]), \"g-\", label=\"$f[x_{1},\\phi]$\")\n",
    "ax.plot(t_all, np.squeeze(f_all[2, :]), \"b-\", label=\"$f[x_{2},\\phi]$\")\n",
    "ax.set_xlim([0, np.max(t_all)])\n",
    "ax.set_ylim([-0.5, 0.5])\n",
    "ax.set_xlabel(\"t\")\n",
    "ax.set_ylabel(\"f\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot residual\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t_all, np.squeeze(f_minus_y_all[0, :]), \"r-\", label=\"$f[x_{0},\\phi]-y_{0}$\")\n",
    "ax.plot(t_all, np.squeeze(f_minus_y_all[1, :]), \"g-\", label=\"$f[x_{1},\\phi]-y_{1}$\")\n",
    "ax.plot(t_all, np.squeeze(f_minus_y_all[2, :]), \"b-\", label=\"$f[x_{2},\\phi]-y_{2}$\")\n",
    "ax.set_xlim([0, np.max(t_all)])\n",
    "ax.set_ylim([-0.5, 0.5])\n",
    "ax.set_xlabel(\"t\")\n",
    "ax.set_ylabel(\"f-y\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Plot loss (sum of residuals)\n",
    "fig, ax = plt.subplots()\n",
    "square_error = 0.5 * np.sum(f_minus_y_all * f_minus_y_all, axis=0)\n",
    "ax.plot(t_all, square_error, \"k-\")\n",
    "ax.set_xlim([0, np.max(t_all)])\n",
    "ax.set_ylim([-0.0, 0.25])\n",
    "ax.set_xlabel(\"t\")\n",
    "ax.set_ylabel(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "# Plot parameters\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(t_all, np.squeeze(phi_t_all[0, :]), \"c-\", label=\"$\\phi_{0}$\")\n",
    "ax.plot(t_all, np.squeeze(phi_t_all[1, :]), \"m-\", label=\"$\\phi_{1}$\")\n",
    "ax.set_xlim([0, np.max(t_all)])\n",
    "ax.set_ylim([-1, 1])\n",
    "ax.set_xlabel(\"t\")\n",
    "ax.set_ylabel(\"$\\phi$\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "G9IwgwKltHz5"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define the model and the loss function"
   ],
   "metadata": {
    "id": "N6VaUq2swa8D"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Model is just a straight line with intercept phi[0] and slope phi[1]\n",
    "def model(phi, x):\n",
    "    y_pred = phi[0] + phi[1] * x\n",
    "    return y_pred\n",
    "\n",
    "\n",
    "# Loss function is 0.5 times sum of squares of residuals for training data\n",
    "def compute_loss(data_x, data_y, model, phi):\n",
    "    pred_y = model(phi, data_x)\n",
    "    loss = 0.5 * np.sum((pred_y - data_y) * (pred_y - data_y))\n",
    "    return loss"
   ],
   "metadata": {
    "id": "LGHEVUWWiB4f"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Draw the loss function"
   ],
   "metadata": {
    "id": "hr3hs7pKwo0g"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def draw_loss_function(compute_loss, X, y, model, phi_iters):\n",
    "    # Define pretty colormap\n",
    "    my_colormap_vals_hex = (\n",
    "        \"2a0902\",\n",
    "        \"2b0a03\",\n",
    "        \"2c0b04\",\n",
    "        \"2d0c05\",\n",
    "        \"2e0c06\",\n",
    "        \"2f0d07\",\n",
    "        \"300d08\",\n",
    "        \"310e09\",\n",
    "        \"320f0a\",\n",
    "        \"330f0b\",\n",
    "        \"34100b\",\n",
    "        \"35110c\",\n",
    "        \"36110d\",\n",
    "        \"37120e\",\n",
    "        \"38120f\",\n",
    "        \"39130f\",\n",
    "        \"3a1410\",\n",
    "        \"3b1411\",\n",
    "        \"3c1511\",\n",
    "        \"3d1612\",\n",
    "        \"3e1613\",\n",
    "        \"3f1713\",\n",
    "        \"401714\",\n",
    "        \"411814\",\n",
    "        \"421915\",\n",
    "        \"431915\",\n",
    "        \"451a16\",\n",
    "        \"461b16\",\n",
    "        \"471b17\",\n",
    "        \"481c17\",\n",
    "        \"491d18\",\n",
    "        \"4a1d18\",\n",
    "        \"4b1e19\",\n",
    "        \"4c1f19\",\n",
    "        \"4d1f1a\",\n",
    "        \"4e201b\",\n",
    "        \"50211b\",\n",
    "        \"51211c\",\n",
    "        \"52221c\",\n",
    "        \"53231d\",\n",
    "        \"54231d\",\n",
    "        \"55241e\",\n",
    "        \"56251e\",\n",
    "        \"57261f\",\n",
    "        \"58261f\",\n",
    "        \"592720\",\n",
    "        \"5b2821\",\n",
    "        \"5c2821\",\n",
    "        \"5d2922\",\n",
    "        \"5e2a22\",\n",
    "        \"5f2b23\",\n",
    "        \"602b23\",\n",
    "        \"612c24\",\n",
    "        \"622d25\",\n",
    "        \"632e25\",\n",
    "        \"652e26\",\n",
    "        \"662f26\",\n",
    "        \"673027\",\n",
    "        \"683027\",\n",
    "        \"693128\",\n",
    "        \"6a3229\",\n",
    "        \"6b3329\",\n",
    "        \"6c342a\",\n",
    "        \"6d342a\",\n",
    "        \"6f352b\",\n",
    "        \"70362c\",\n",
    "        \"71372c\",\n",
    "        \"72372d\",\n",
    "        \"73382e\",\n",
    "        \"74392e\",\n",
    "        \"753a2f\",\n",
    "        \"763a2f\",\n",
    "        \"773b30\",\n",
    "        \"783c31\",\n",
    "        \"7a3d31\",\n",
    "        \"7b3e32\",\n",
    "        \"7c3e33\",\n",
    "        \"7d3f33\",\n",
    "        \"7e4034\",\n",
    "        \"7f4134\",\n",
    "        \"804235\",\n",
    "        \"814236\",\n",
    "        \"824336\",\n",
    "        \"834437\",\n",
    "        \"854538\",\n",
    "        \"864638\",\n",
    "        \"874739\",\n",
    "        \"88473a\",\n",
    "        \"89483a\",\n",
    "        \"8a493b\",\n",
    "        \"8b4a3c\",\n",
    "        \"8c4b3c\",\n",
    "        \"8d4c3d\",\n",
    "        \"8e4c3e\",\n",
    "        \"8f4d3f\",\n",
    "        \"904e3f\",\n",
    "        \"924f40\",\n",
    "        \"935041\",\n",
    "        \"945141\",\n",
    "        \"955242\",\n",
    "        \"965343\",\n",
    "        \"975343\",\n",
    "        \"985444\",\n",
    "        \"995545\",\n",
    "        \"9a5646\",\n",
    "        \"9b5746\",\n",
    "        \"9c5847\",\n",
    "        \"9d5948\",\n",
    "        \"9e5a49\",\n",
    "        \"9f5a49\",\n",
    "        \"a05b4a\",\n",
    "        \"a15c4b\",\n",
    "        \"a35d4b\",\n",
    "        \"a45e4c\",\n",
    "        \"a55f4d\",\n",
    "        \"a6604e\",\n",
    "        \"a7614e\",\n",
    "        \"a8624f\",\n",
    "        \"a96350\",\n",
    "        \"aa6451\",\n",
    "        \"ab6552\",\n",
    "        \"ac6552\",\n",
    "        \"ad6653\",\n",
    "        \"ae6754\",\n",
    "        \"af6855\",\n",
    "        \"b06955\",\n",
    "        \"b16a56\",\n",
    "        \"b26b57\",\n",
    "        \"b36c58\",\n",
    "        \"b46d59\",\n",
    "        \"b56e59\",\n",
    "        \"b66f5a\",\n",
    "        \"b7705b\",\n",
    "        \"b8715c\",\n",
    "        \"b9725d\",\n",
    "        \"ba735d\",\n",
    "        \"bb745e\",\n",
    "        \"bc755f\",\n",
    "        \"bd7660\",\n",
    "        \"be7761\",\n",
    "        \"bf7862\",\n",
    "        \"c07962\",\n",
    "        \"c17a63\",\n",
    "        \"c27b64\",\n",
    "        \"c27c65\",\n",
    "        \"c37d66\",\n",
    "        \"c47e67\",\n",
    "        \"c57f68\",\n",
    "        \"c68068\",\n",
    "        \"c78169\",\n",
    "        \"c8826a\",\n",
    "        \"c9836b\",\n",
    "        \"ca846c\",\n",
    "        \"cb856d\",\n",
    "        \"cc866e\",\n",
    "        \"cd876f\",\n",
    "        \"ce886f\",\n",
    "        \"ce8970\",\n",
    "        \"cf8a71\",\n",
    "        \"d08b72\",\n",
    "        \"d18c73\",\n",
    "        \"d28d74\",\n",
    "        \"d38e75\",\n",
    "        \"d48f76\",\n",
    "        \"d59077\",\n",
    "        \"d59178\",\n",
    "        \"d69279\",\n",
    "        \"d7937a\",\n",
    "        \"d8957b\",\n",
    "        \"d9967b\",\n",
    "        \"da977c\",\n",
    "        \"da987d\",\n",
    "        \"db997e\",\n",
    "        \"dc9a7f\",\n",
    "        \"dd9b80\",\n",
    "        \"de9c81\",\n",
    "        \"de9d82\",\n",
    "        \"df9e83\",\n",
    "        \"e09f84\",\n",
    "        \"e1a185\",\n",
    "        \"e2a286\",\n",
    "        \"e2a387\",\n",
    "        \"e3a488\",\n",
    "        \"e4a589\",\n",
    "        \"e5a68a\",\n",
    "        \"e5a78b\",\n",
    "        \"e6a88c\",\n",
    "        \"e7aa8d\",\n",
    "        \"e7ab8e\",\n",
    "        \"e8ac8f\",\n",
    "        \"e9ad90\",\n",
    "        \"eaae91\",\n",
    "        \"eaaf92\",\n",
    "        \"ebb093\",\n",
    "        \"ecb295\",\n",
    "        \"ecb396\",\n",
    "        \"edb497\",\n",
    "        \"eeb598\",\n",
    "        \"eeb699\",\n",
    "        \"efb79a\",\n",
    "        \"efb99b\",\n",
    "        \"f0ba9c\",\n",
    "        \"f1bb9d\",\n",
    "        \"f1bc9e\",\n",
    "        \"f2bd9f\",\n",
    "        \"f2bfa1\",\n",
    "        \"f3c0a2\",\n",
    "        \"f3c1a3\",\n",
    "        \"f4c2a4\",\n",
    "        \"f5c3a5\",\n",
    "        \"f5c5a6\",\n",
    "        \"f6c6a7\",\n",
    "        \"f6c7a8\",\n",
    "        \"f7c8aa\",\n",
    "        \"f7c9ab\",\n",
    "        \"f8cbac\",\n",
    "        \"f8ccad\",\n",
    "        \"f8cdae\",\n",
    "        \"f9ceb0\",\n",
    "        \"f9d0b1\",\n",
    "        \"fad1b2\",\n",
    "        \"fad2b3\",\n",
    "        \"fbd3b4\",\n",
    "        \"fbd5b6\",\n",
    "        \"fbd6b7\",\n",
    "        \"fcd7b8\",\n",
    "        \"fcd8b9\",\n",
    "        \"fcdaba\",\n",
    "        \"fddbbc\",\n",
    "        \"fddcbd\",\n",
    "        \"fddebe\",\n",
    "        \"fddfbf\",\n",
    "        \"fee0c1\",\n",
    "        \"fee1c2\",\n",
    "        \"fee3c3\",\n",
    "        \"fee4c5\",\n",
    "        \"ffe5c6\",\n",
    "        \"ffe7c7\",\n",
    "        \"ffe8c9\",\n",
    "        \"ffe9ca\",\n",
    "        \"ffebcb\",\n",
    "        \"ffeccd\",\n",
    "        \"ffedce\",\n",
    "        \"ffefcf\",\n",
    "        \"fff0d1\",\n",
    "        \"fff2d2\",\n",
    "        \"fff3d3\",\n",
    "        \"fff4d5\",\n",
    "        \"fff6d6\",\n",
    "        \"fff7d8\",\n",
    "        \"fff8d9\",\n",
    "        \"fffada\",\n",
    "        \"fffbdc\",\n",
    "        \"fffcdd\",\n",
    "        \"fffedf\",\n",
    "        \"ffffe0\",\n",
    "    )\n",
    "    my_colormap_vals_dec = np.array(\n",
    "        [int(element, base=16) for element in my_colormap_vals_hex]\n",
    "    )\n",
    "    r = np.floor(my_colormap_vals_dec / (256 * 256))\n",
    "    g = np.floor((my_colormap_vals_dec - r * 256 * 256) / 256)\n",
    "    b = np.floor(my_colormap_vals_dec - r * 256 * 256 - g * 256)\n",
    "    my_colormap = ListedColormap(np.vstack((r, g, b)).transpose() / 255.0)\n",
    "\n",
    "    # Make grid of intercept/slope values to plot\n",
    "    intercepts_mesh, slopes_mesh = np.meshgrid(\n",
    "        np.arange(-1.0, 1.0, 0.005), np.arange(-1.0, 1.0, 0.005)\n",
    "    )\n",
    "    loss_mesh = np.zeros_like(slopes_mesh)\n",
    "    # Compute loss for every set of parameters\n",
    "    for idslope, slope in np.ndenumerate(slopes_mesh):\n",
    "        loss_mesh[idslope] = compute_loss(\n",
    "            X, y, model, np.array([[intercepts_mesh[idslope]], [slope]])\n",
    "        )\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    fig.set_size_inches(8, 8)\n",
    "    ax.contourf(intercepts_mesh, slopes_mesh, loss_mesh, 256, cmap=my_colormap)\n",
    "    ax.contour(intercepts_mesh, slopes_mesh, loss_mesh, 40, colors=[\"#80808080\"])\n",
    "    ax.set_ylim([1, -1])\n",
    "    ax.set_xlim([-1, 1])\n",
    "\n",
    "    ax.plot(phi_iters[1, :], phi_iters[0, :], \"g-\")\n",
    "    ax.set_xlabel(\"Intercept\")\n",
    "    ax.set_ylabel(\"Slope\")\n",
    "    plt.show()"
   ],
   "metadata": {
    "id": "UCxa3tZ8a9kz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "draw_loss_function(compute_loss, X[0:1, :], y.T, model, phi_t_all)"
   ],
   "metadata": {
    "id": "pXLLBaSaiI2A"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Draw the evolution of the function"
   ],
   "metadata": {
    "id": "ZsremHW-xFi5"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(X[0:1, :], y.T, \"ro\")\n",
    "x_vals = np.arange(0, 1, 0.001)\n",
    "ax.plot(x_vals, phi_t_all[0, 0] * x_vals + phi_t_all[1, 0], \"r-\", label=\"t=0.00\")\n",
    "ax.plot(x_vals, phi_t_all[0, 10] * x_vals + phi_t_all[1, 10], \"g-\", label=\"t=0.10\")\n",
    "ax.plot(x_vals, phi_t_all[0, 30] * x_vals + phi_t_all[1, 30], \"b-\", label=\"t=0.30\")\n",
    "ax.plot(x_vals, phi_t_all[0, 200] * x_vals + phi_t_all[1, 200], \"c-\", label=\"t=2.00\")\n",
    "ax.plot(x_vals, phi_t_all[0, 1999] * x_vals + phi_t_all[1, 1999], \"y-\", label=\"t=20.0\")\n",
    "ax.set_xlim([0, 1])\n",
    "ax.set_ylim([-0.5, 0.5])\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ],
   "metadata": {
    "id": "cv9ZrUoRkuhI"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Compute MAP and ML solutions\n",
    "MLParams = np.linalg.inv(X @ X.T) @ X @ y\n",
    "sigma_sq_p = 3.0\n",
    "sigma_sq = 0.05\n",
    "MAPParams = (\n",
    "    np.linalg.inv(X @ X.T + np.identity(X.shape[0]) * sigma_sq / sigma_sq_p) @ X @ y\n",
    ")"
   ],
   "metadata": {
    "id": "OU9oegSOof-o"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Finally, we predict both the mean and the uncertainty in the fitted model as a function of time"
   ],
   "metadata": {
    "id": "Ul__XvOgyYSA"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Define x positions to make predictions (appending a 1 to each column)\n",
    "x_predict = np.arange(0, 1, 0.01)[None, :]\n",
    "x_predict = np.concatenate((x_predict, np.ones_like(x_predict)))\n",
    "nX = x_predict.shape[1]\n",
    "\n",
    "# Create variables to store evolution of mean and variance of prediction over time\n",
    "predict_mean_all = np.zeros((nT, nX))\n",
    "predict_var_all = np.zeros((nT, nX))\n",
    "\n",
    "# Initial covariance\n",
    "sigma_sq_p = 2.0\n",
    "cov_init = sigma_sq_p * np.identity(2)\n",
    "\n",
    "# Run through each time computing a and b and hence mean and variance of prediction\n",
    "for t in range(len(t_all)):\n",
    "    a = x_predict.T @ (XXTInvX @ (np.identity(3) - expm(-X.T @ X * t_all[t])) @ y)\n",
    "    b = (\n",
    "        x_predict.T\n",
    "        - x_predict.T @ XXTInvX @ (np.identity(3) - expm(-X.T @ X * t_all[t])) @ X.T\n",
    "    )\n",
    "    predict_mean_all[t : t + 1, :] = a.T\n",
    "    predict_cov = b @ cov_init @ b.T\n",
    "    # We just want the diagonal of the covariance to plot the uncertainty\n",
    "    predict_var_all[t : t + 1, :] = np.reshape(np.diag(predict_cov), (1, nX))"
   ],
   "metadata": {
    "id": "aMPADCuByKWr"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot the mean and variance at various times"
   ],
   "metadata": {
    "id": "PZTj93KK7QH6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def plot_mean_var(\n",
    "    X, y, x_predict, predict_mean_all, predict_var_all, this_t, sigma_sq=0.00001\n",
    "):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(X[0:1, :], y.T, \"ro\")\n",
    "    ax.plot(x_predict[0:1, :].T, predict_mean_all[this_t : this_t + 1, :].T, \"r-\")\n",
    "    lower = np.squeeze(\n",
    "        predict_mean_all[this_t : this_t + 1, :].T\n",
    "        - np.sqrt(predict_var_all[this_t : this_t + 1, :].T + np.sqrt(sigma_sq))\n",
    "    )\n",
    "    upper = np.squeeze(\n",
    "        predict_mean_all[this_t : this_t + 1, :].T\n",
    "        + np.sqrt(predict_var_all[this_t : this_t + 1, :].T + np.sqrt(sigma_sq))\n",
    "    )\n",
    "    ax.fill_between(np.squeeze(x_predict[0:1, :]), lower, upper, color=\"lightgray\")\n",
    "    ax.set_xlim([0, 1])\n",
    "    ax.set_ylim([-0.5, 0.5])\n",
    "    ax.set_xlabel(\"x\")\n",
    "    ax.set_ylabel(\"y\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_mean_var(X, y, x_predict, predict_mean_all, predict_var_all, this_t=0)\n",
    "plot_mean_var(X, y, x_predict, predict_mean_all, predict_var_all, this_t=40)\n",
    "plot_mean_var(X, y, x_predict, predict_mean_all, predict_var_all, this_t=80)\n",
    "plot_mean_var(X, y, x_predict, predict_mean_all, predict_var_all, this_t=200)\n",
    "plot_mean_var(X, y, x_predict, predict_mean_all, predict_var_all, this_t=500)\n",
    "plot_mean_var(X, y, x_predict, predict_mean_all, predict_var_all, this_t=1000)"
   ],
   "metadata": {
    "id": "bYAFxgB880-v"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}